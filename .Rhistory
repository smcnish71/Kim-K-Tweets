import(shiny)
install.packages(shiny)
install.packages("shiny")
library(shiny)
ui<- fluidPage()
server <- function(input, output) {}
shinyApp(ui= ui , server = server)
install.packages('rsconnect')
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
rsconnect::setAccountInfo(name='smcnish71', token='BAE95C8CA912B052BDE57EC808E9A955', secret='rL+9cm6rkX5VnY6jfEAlVPigagEJJwdQuGWaeuk8')
library(rsconnect)
rsconnect::deployApp('path/to/your/app')
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(devtools)
install_github('slidify', 'smcnish/slidifyLibraries')
install_github('slidifyLibraries', 'smcnish/slidifyLibraries')
library(devtools)
2.install_github('slidify', 'ramnathv')
3.install_github('slidifyLibraries', 'ramnathv')
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
author("mydeck")
setwd("~/Vizs/Kim")
?read.csv
Data<- read.csv(KimKardashianTweets.csv, header=TRUE, stringsAsFactors = FALSE)
Data<- read.csv('KimKardashianTweets.csv', header=TRUE, stringsAsFactors = FALSE)
head(Data)
tail(Data)
data<- read.csv('KimKardashianTweets.csv', header=TRUE, stringsAsFactors = FALSE)
View(Data)
View(data)
data$text <- gsub("[0-9]", "", dataset$text) #all the numeric values
data$text <- gsub("RT*", "", dataset$text) #all the RT, if there are.
data$text <- gsub("[^\x20-\x7E]", "", dataset$text) #all the unrelated characters
data$text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", dataset$text) #all the hyperlinks
#clean up variables with regex
data$text <- gsub("[0-9]", "", data$text) #all the numeric values
data$text <- gsub("RT*", "", datat$text) #all the RT, if there are.
data$text <- gsub("[^\x20-\x7E]", "", data$text) #all the unrelated characters
data$text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", data$text) #all the hyperlinks
data$text <- gsub("[0-9]", "", data$text) #all the numeric values
data$text <- gsub("RT*", "", data$text) #all the RT, if there are.
data$text <- gsub("[^\x20-\x7E]", "", data$text) #all the unrelated characters
data$text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", data$text) #all the hyperlinks
sentiment_scores = function(tweets, positive_words, negative_words, .progress='none'){
scores = laply(tweets,
function(tweet, positive_words, negative_words){
# Let's have error handling function when trying tolower
tryTolower = function(x){
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
tweet = sapply(tweet, tryTolower)
# split sentence into words with str_split function from stringr package
word_list = str_split(tweet, "\s+")
words = unlist(word_list)
# compare words to the dictionaries of positive & negative terms
positive.matches = match(words, positive_words)
negative.matches = match(words, negative_words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
positive_matches = !is.na(positive_matches)
negative_matches = !is.na(negative_matches)
# final score
score = sum(positive_matches) - sum(negative_matches)
return(score)
}, positive_matches, negative_matches, .progress=.progress )
return(scores)
}
score = sentiment_scores(tweet, positives, negatives, .progress='text')
data$score=score
setwd("~/Vizs/Kim")
data<- read.csv('KimKardashianTweets.csv', header=TRUE, stringsAsFactors = FALSE)
#clean up variables with regex
data$text <- gsub("[0-9]", "", data$text) #all the numeric values
data$text <- gsub("RT*", "", data$text) #all the RT, if there are.
data$text <- gsub("[^\x20-\x7E]", "", data$text) #all the unrelated characters
data$text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", data$text) #all the hyperlinks
data$text <- gsub("+(pic)?[.]twitter[.]+(.*)", "", data$text) #the pics
data$text <- gsub("[@#+$//-]", "", data$text) #hash's
data$text <- gsub("[[:punct:]]", "", data$text) #punctuation.
data$text = gsub("[[:cntrl:]]", "", data$text)   # control characters
positives= readLines("positive-words.txt")
negatives = readLines("negative-words.txt")
sentiment_scores = function(tweets, positive_words, negative_words, .progress='none'){
scores = laply(tweets,
function(tweet, positive_words, negative_words){
# Let's have error handling function when trying tolower
tryTolower = function(x){
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
tweet = sapply(tweet, tryTolower)
# split sentence into words with str_split function from stringr package
word_list = str_split(tweet, "\s+")
words = unlist(word_list)
# compare words to the dictionaries of positive & negative terms
positive.matches = match(words, positive_words)
negative.matches = match(words, negative_words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
positive_matches = !is.na(positive_matches)
negative_matches = !is.na(negative_matches)
# final score
score = sum(positive_matches) - sum(negative_matches)
return(score)
}, positive_matches, negative_matches, .progress=.progress )
return(scores)
}
score = sentiment_scores(tweet, positives, negatives, .progress='text')
data$score=score
sentiment_scores = function(tweets, positive_words, negative_words, .progress='none'){
scores = laply(tweets,
function(text, positive_words, negative_words){
# Let's have error handling function when trying tolower
tryTolower = function(x){
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
text = sapply(text, tryTolower)
# split sentence into words with str_split function from stringr package
word_list = str_split(text, "\s+")
words = unlist(word_list)
# compare words to the dictionaries of positive & negative terms
positive.matches = match(words, positive_words)
negative.matches = match(words, negative_words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
positive_matches = !is.na(positive_matches)
negative_matches = !is.na(negative_matches)
# final score
score = sum(positive_matches) - sum(negative_matches)
return(score)
}, positive_matches, negative_matches, .progress=.progress )
return(scores)
}
score = sentiment_scores(text, positives, negatives, .progress='text')
sentiment_scores = function(tweets, positive_words, negative_words, .progress='none'){
scores = laply(tweets,
function(text, positive_words, negative_words){
# Let's have error handling function when trying tolower
tryTolower = function(x){
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
text = sapply(text, tryTolower)
# split sentence into words with str_split function from stringr package
word_list = str_split(text, "\\s+")
words = unlist(word_list)
# compare words to the dictionaries of positive & negative terms
positive.matches = match(words, positive_words)
negative.matches = match(words, negative_words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
positive_matches = !is.na(positive_matches)
negative_matches = !is.na(negative_matches)
# final score
score = sum(positive_matches) - sum(negative_matches)
return(score)
}, positive_matches, negative_matches, .progress=.progress )
return(scores)
}
score = sentiment_scores(text, positives, negatives, .progress='text')
data$score=score
library (plyr)
sentiment_scores = function(tweets, positive_words, negative_words, .progress='none'){
scores = laply(tweets,
function(text, positive_words, negative_words){
# Let's have error handling function when trying tolower
tryTolower = function(x){
# create missing value
y = NA
# tryCatch error
try_error = tryCatch(tolower(x), error=function(e) e)
# if not an error
if (!inherits(try_error, "error"))
y = tolower(x)
# result
return(y)
}
# use tryTolower with sapply
text = sapply(text, tryTolower)
# split sentence into words with str_split function from stringr package
word_list = str_split(text, "\\s+")
words = unlist(word_list)
# compare words to the dictionaries of positive & negative terms
positive.matches = match(words, positive_words)
negative.matches = match(words, negative_words)
# get the position of the matched term or NA
# we just want a TRUE/FALSE
positive_matches = !is.na(positive_matches)
negative_matches = !is.na(negative_matches)
# final score
score = sum(positive_matches) - sum(negative_matches)
return(score)
}, positive_matches, negative_matches, .progress=.progress )
return(scores)
}
score = sentiment_scores(text, positives, negatives, .progress='text')
data$score=score
pos.words= readLines("positive-words.txt")
neg.words = readLines("negative-words.txt")
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of tweets plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(tweets, function(text, pos.words, neg.words) {
# and convert to lower case:
text = tolower(text)
# split into words. str_split is in the stringr package
word.list = str_split(text, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
neg.matches = match(words, neg.words)
pos.matches = match(words, pos.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
pos.words= readLines("positive-words.txt")
neg.words = readLines("negative-words.txt")
pos=scan('positive-words.txt', what='character',comment.char=';')
pos= scan('positive-words.txt', what='character',comment.char=';')
neg = scan('negative-words.txt', what='character',comment.char=';')
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of tweets plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(tweets, function(text, pos.words, neg.words) {
# and convert to lower case:
text = tolower(text)
# split into words. str_split is in the stringr package
word.list = str_split(text, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
neg.matches = match(words, neg.words)
pos.matches = match(words, pos.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
analysis = score.sentiment(data$text, pos, neg)
head(analysis)
setwd("~/Vizs/Kim")
data<- read.csv('KimKardashianTweets.csv', header=TRUE, stringsAsFactors = FALSE)
library (plyr)
#clean up variables with regex
data$text <- gsub("[0-9]", "", data$text) #all the numeric values
data$text <- gsub("RT*", "", data$text) #all the RT, if there are.
data$text <- gsub("[^\x20-\x7E]", "", data$text) #all the unrelated characters
data$text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", data$text) #all the hyperlinks
data$text <- gsub("+(pic)?[.]twitter[.]+(.*)", "", data$text) #the pics
data$text <- gsub("[@#+$//-]", "", data$text) #hash's
data$text <- gsub("[[:punct:]]", "", data$text) #punctuation.
data$text = gsub("[[:cntrl:]]", "", data$text)   # control characters
#Sentiment Anlaysis
pos= scan('positive-words.txt', what='character',comment.char=';')
neg = scan('negative-words.txt', what='character',comment.char=';')
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of tweets plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(tweets, function(text, pos.words, neg.words) {
# and convert to lower case:
text = tolower(text)
# split into words. str_split is in the stringr package
word.list = str_split(text, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
neg.matches = match(words, neg.words)
pos.matches = match(words, pos.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
data_scores = score.sentiment(data$text, pos, neg)
setwd("~/Vizs/Kim")
data<- read.csv('KimKardashianTweets.csv', header=TRUE, stringsAsFactors = FALSE)
#Sentiment Anlaysis
pos= scan('positive-words.txt', what='character',comment.char=';')
neg = scan('negative-words.txt', what='character',comment.char=';')
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of tweets plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(tweets, function(text, pos.words, neg.words) {
#clean up variables with regex
data$text <- gsub("[0-9]", "", data$text) #all the numeric values
data$text <- gsub("RT*", "", data$text) #all the RT, if there are.
data$text <- gsub("[^\x20-\x7E]", "", data$text) #all the unrelated characters
data$text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", data$text) #all the hyperlinks
data$text <- gsub("+(pic)?[.]twitter[.]+(.*)", "", data$text) #the pics
data$text <- gsub("[@#+$//-]", "", data$text) #hash's
data$text <- gsub("[[:punct:]]", "", data$text) #punctuation.
data$text = gsub("[[:cntrl:]]", "", data$text)   # control characters
# and convert to lower case:
text = tolower(text)
# split into words. str_split is in the stringr package
word.list = str_split(text, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
neg.matches = match(words, neg.words)
pos.matches = match(words, pos.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
data_scores = score.sentiment(data$text, pos, neg)
setwd("~/Vizs/Kim")
data<- read.csv('KimKardashianTweets.csv', header=TRUE, stringsAsFactors = FALSE)
#Sentiment Anlaysis
pos= scan('positive-words.txt', what='character',comment.char=';')
neg = scan('negative-words.txt', what='character',comment.char=';')
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of tweets plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(tweets, function(text, pos.words, neg.words) {
#clean up variables with regex
text <- gsub("[0-9]", "", text) #all the numeric values
text <- gsub("RT*", "", text) #all the RT, if there are.
text <- gsub("[^\x20-\x7E]", "", text) #all the unrelated characters
text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", text) #all the hyperlinks
text <- gsub("+(pic)?[.]twitter[.]+(.*)", "", text) #the pics
text <- gsub("[@#+$//-]", "", text) #hash's
text <- gsub("[[:punct:]]", "", text) #punctuation.
text = gsub("[[:cntrl:]]", "", text)   # control characters
# and convert to lower case:
text = tolower(text)
# split into words. str_split is in the stringr package
word.list = str_split(text, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
neg.matches = match(words, neg.words)
pos.matches = match(words, pos.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
data_scores = score.sentiment(data$text, pos, neg)
#Sentiment Anlaysis
pos= scan('positive-words.txt', what='character',comment.char=';')
neg = scan('negative-words.txt', what='character',comment.char=';')
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of tweets plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(tweets, function(text, pos.words, neg.words) {
#clean up variables with regex
text <- gsub("[0-9]", "", text) #all the numeric values
text <- gsub("RT*", "", text) #all the RT, if there are.
text <- gsub("[^\x20-\x7E]", "", text) #all the unrelated characters
text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", text) #all the hyperlinks
text <- gsub("+(pic)?[.]twitter[.]+(.*)", "", text) #the pics
text <- gsub("[@#+$//-]", "", text) #hash's
text <- gsub("[[:punct:]]", "", text) #punctuation.
text = gsub("[[:cntrl:]]", "", text)   # control characters
# and convert to lower case:
text = tolower(text)
# split into words. str_split is in the stringr package
word.list = str_split(text, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
neg.matches = match(words, neg.words)
pos.matches = match(words, pos.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=tweets, X=X, date = date, link=link)
return(scores.df)
}
data_scores = score.sentiment(data$text, pos, neg)
setwd("~/Vizs/Kim")
data<- read.csv('KimKardashianTweets.csv', header=TRUE, stringsAsFactors = FALSE)
#Sentiment Anlaysis
pos= scan('positive-words.txt', what='character',comment.char=';')
neg = scan('negative-words.txt', what='character',comment.char=';')
score.sentiment = function(tweets, pos.words, neg.words, .progress='none')
{
require(plyr)
require(stringr)
# we got a vector of tweets plyr will handle a list or a vector as an "l" for us
# we want a simple array of scores back, so we use "l" + "a" + "ply" = laply:
scores = laply(tweets, function(text, pos.words, neg.words) {
#clean up variables with regex
text <- gsub("[0-9]", "", text) #all the numeric values
text <- gsub("RT*", "", text) #all the RT, if there are.
text <- gsub("[^\x20-\x7E]", "", text) #all the unrelated characters
text <- gsub(" ?(www|ht)tp(s?)://(.*)[.][a-z]+", "", text) #all the hyperlinks
text <- gsub("+(pic)?[.]twitter[.]+(.*)", "", text) #the pics
text <- gsub("[@#+$//-]", "", text) #hash's
text <- gsub("[[:punct:]]", "", text) #punctuation.
text = gsub("[[:cntrl:]]", "", text)   # control characters
# and convert to lower case:
text = tolower(text)
# split into words. str_split is in the stringr package
word.list = str_split(text, '\\s+')
# sometimes a list() is one level of hierarchy too much
words = unlist(word.list)
# compare our words to the dictionaries of positive & negative terms
neg.matches = match(words, neg.words)
pos.matches = match(words, pos.words)
# match() returns the position of the matched term or NA
# we just want a TRUE/FALSE:
pos.matches = !is.na(pos.matches)
neg.matches = !is.na(neg.matches)
# and conveniently enough, TRUE/FALSE will be treated as 1/0 by sum():
score = sum(pos.matches) - sum(neg.matches)
return(score)
}, pos.words, neg.words, .progress=.progress )
scores.df = data.frame(score=scores, text=tweets)
return(scores.df)
}
data_scores = score.sentiment(data$text, pos, neg)
hist(data_scores$score)
table(data_scores$score)
data_scores<- merge(data,data_scores, by="text")
